services:

  firefox:
    image: selenium/standalone-firefox:4.16.1-20231219
    restart: on-failure
    container_name: firefox
    shm_size: 2g
    ports:
      - "4444:4444"
      - "7900:7900"
    networks:
      - common-network
    volumes:
      - selenium-data:/home/seluser/Downloads
    environment:
      - SE_SESSION_REQUEST_TIMEOUT=3600
      - SE_NODE_SESSION_TIMEOUT=3600
      - SE_VNC_PASSWORD=1234
      - SE_NODE_OVERRIDE_MAX_SESSIONS=true 
      - SE_NODE_MAX_SESSIONS=5
    deploy:
      resources:
        limits:
          cpus: '0.4'

  django_fastapi:
    build: .
    pull_policy: build
    restart: always
    cpus: '2.0'
    # ports:
    #  - '8000:8000'
    networks:
      - common-network
    environment:
      - POSTGRES_HOST=psql_db
      - SELENIUM_DRIVER=firefox
      - REDIS_HOST=redis_db
      - PGBOUNCER_HOST=pgbouncer
    env_file:
      - ./.env
    # container_name: django_fastapi
    depends_on:
      - psql_db
      - pgbouncer
      # - redis_db
      # - celery_worker
      - firefox
    logging:
      driver: "json-file"
      options:
          max-size: "20m"
    volumes:
      - static:/app/staticfiles
      - media:/app/media
    command: sh -c "python manage.py makemigrations &&
                    python manage.py migrate &&
                    gunicorn -w 2 -k uvicorn.workers.UvicornWorker project.asgi:app --bind 0.0.0.0:8000 --timeout 180 --error-logfile /app/logs/gunicorn-error.log"
                    # python manage.py periodic_task_exchange_admin_notifications &&
                    # uvicorn project.asgi:app --host 0.0.0.0"
                    # uvicorn project.asgi:app \
                    # --host 0.0.0.0 \
                    # --port 8000 \
                    # --workers 4 \
                    # --timeout-keep-alive 60 \
                    # --loop uvloop"
                    # python manage.py collectstatic --no-input &&
                    # python manage.py create_new_reviews_from_old &&
                    # python manage.py parse_reviews_selenium &&
                    # python manage.py add_time_create_for_exchanges &&
                    # python manage.py create_moder_group &&
                    # python manage.py create_periodic_task_for_update_exchange_info &&
                    # python manage.py create_periodic_task_for_parse_actual_course &&
                    # python manage.py loaddata media/base_db.json &&
                    # python manage.py loaddata media/countries.json &&
                    # python manage.py create_popular_directions_group &&
                    # python manage.py create_periodic_task_for_delete_reviews &&
                    # python manage.py create_cities &&
                    # python manage.py create_moderator_group &&
                    # python manage.py createsuperuser --no-input &&
                    # python manage.py periodic_task_for_parse_cash_courses &&
                    # python manage.py recreate_backround_tasks &&

  nginx:
    build: ./nginx
    restart: always
    container_name: nginx
    cpus: '0.5'
    networks:
      - common-network
    volumes:
      - static:/static
      - media:/media
      - ./nginx/certs:/etc/nginx/certs
    ports:
      # - '81:80'
      - '80:80'
      - '443:443'
    depends_on:
      - django_fastapi
    logging:
      driver: "json-file"
      options:
          max-size: "20m"

  redis_db:
    image: redis:latest
    restart: always
    cpus: '0.5'
    networks:
      - common-network
    # ports:
    #   - 6379:6379
    env_file:
      - ./.env
    command: redis-server --requirepass ${REDIS_PASSWORD} --save "" --appendonly no
    # sh -c "echo 1 > /proc/sys/vm/overcommit_memory && redis-server --save 900 1 --loglevel warning"
    volumes:
      - redis_data:/data
    logging:
      driver: "json-file"
      options:
          max-size: "20m"

  # rabbitmq3:
  #   image: rabbitmq:management
  #   ports:
  #     - '5672:5672'
  #     - '15672:15672'
  #   volumes:
  #     - rabbitmq_data:/var/lib/rabbitmq
  #   logging:
  #     driver: "json-file"
  #     options:
  #         max-size: "20m"
  #   networks:
  #     - common-network

  celery_worker:
    build: .
    pull_policy: build
    restart: always
    networks:
      - common-network
    command: sh -c 'celery -A project worker -l info -c 4'
    environment:
      - POSTGRES_HOST=psql_db
      - SELENIUM_DRIVER=firefox
      - REDIS_HOST=redis_db
      - PGBOUNCER_HOST=pgbouncer
    env_file:
      - ./.env
    depends_on:
      - redis_db
      - psql_db
      - pgbouncer
      # - rabbitmq3
      - firefox
    cpus: '2.0'
    logging:
      driver: "json-file"
      options:
          max-size: "20m"
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '1.0'


  celery_beat:
    build: .
    pull_policy: build
    restart: always
    networks:
      - common-network
    command: sh -c 'celery -A project beat -l INFO --scheduler django_celery_beat.schedulers:DatabaseScheduler'
    environment:
      - POSTGRES_HOST=psql_db
      - REDIS_HOST=redis_db
      - PGBOUNCER_HOST=pgbouncer
    cpus: '0.5'
    env_file:
      - ./.env
    depends_on:
      - redis_db
      - psql_db
      - pgbouncer
      - celery_worker
      # - rabbitmq3
    logging:
      driver: "json-file"
      options:
          max-size: "20m"

  flower:
    build: .
    restart: always
    command: sh -c 'celery -A project flower'
    cpus: '0.5'
    networks:
      - common-network
    environment:
      - POSTGRES_HOST=psql_db
      - SELENIUM_DRIVER=firefox
      - REDIS_HOST=redis_db
      - PGBOUNCER_HOST=pgbouncer
    env_file:
      - ./.env
    volumes:
      - flower_data:/data
    ports:
      - '5554:5555'

  psql_db:
    image: postgres:14
    restart: always
    networks:
      - common-network
    # ports:
    #   - '5432:5432'
    env_file:
      - ./.env
    cpus: '2.0'
    mem_limit: 10g
    shm_size: '4g'
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # command: postgres -c max_connections=200 -c shared_buffers=2GB
    # command: postgres -c max_connections=100 -c shared_buffers=2GB -c work_mem=16MB -c maintenance_work_mem=512MB -c effective_cache_size=6GB
    command: postgres -c max_connections=80 -c shared_buffers=1GB -c work_mem=2MB -c maintenance_work_mem=128MB -c effective_cache_size=7GB
    logging:
      driver: "json-file"
      options:
          max-size: "20m"

  pgbouncer:
    image: edoburu/pgbouncer
    restart: always
    cpus: '0.5' 
    env_file:
      - ./.env
    # environment:
    #   DATABASE_URL: postgres://postgres:os6ARnMaXLPMFPqsbb@psql_db:5432/postgres
      # PGBOUNCER_USER: your_user
      # PGBOUNCER_PASSWORD: your_password
    ports:
      - "5432:5432"  # Порт для PgBouncer
    networks:
      - common-network
    volumes:
      - ./pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini
      # - ./pgbouncer_hba.conf:/etc/pgbouncer/pgbouncer_hba.conf
      - ./userlist.txt:/etc/pgbouncer/userlist.txt
      - pgbouncer_data:/var/run/pgbouncer

volumes:
  selenium-data:
  postgres-data:
  redis_data:
  # rabbitmq_data:
  flower_data:
  static:
  media:
  pgbouncer_data:

networks:
  common-network:
    driver: bridge